{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf703b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shirl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f7a678",
   "metadata": {},
   "source": [
    "# Kleine database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155d198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'?', 'i', 'H', 'N', '0', 'G', 'p', 'V', '4', 'z', 'U', 'K', 'L', 'n', 'B', 'w', 'r', 'A', 'x', '8', 'd', '(', 'm', ')', 'o', 'D', 'v', \"'\", 'j', 'Z', 'f', '-', 's', 'E', 'g', 'q', 'h', 'c', 'y', 'R', 'P', 'M', '.', 'u', '1', 'F', 'W', '!', '9', 'I', 'S', '3', 'T', 'a', 'k', 't', 'J', 'l', '7', 'C', '2', ',', ' ', 'Y', 'e', 'b', 'O'}\n",
      "Test Accuracy:  0.4444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.62         4\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.44         9\n",
      "   macro avg       0.22      0.50      0.31         9\n",
      "weighted avg       0.20      0.44      0.27         9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-919f04eeb7e4>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"Gecleand\"] = df['input'].str.replace('[^\\w\\s]','')\n",
      "<ipython-input-8-919f04eeb7e4>:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
      "<ipython-input-8-919f04eeb7e4>:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
      "C:\\Users\\shirl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shirl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shirl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"C:\\\\Users\\\\shirl\\\\Desktop\\\\MovieReactionDS_small.json\")\n",
    "\n",
    "#Controleren op null waardes\n",
    "df.isna().sum()\n",
    "\n",
    "#LEESTEKENS \n",
    "df[\"Gecleand\"] = df['input'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#De kolom `Gecleand` alles in kleine letters zetten\n",
    "df['Gecleand'] = df['Gecleand'].str.lower()\n",
    "#print(df)\n",
    "\n",
    "#stopwoorden eruit halen\n",
    "stop = stopwords.words('english')\n",
    "df['Gecleand'] = df['Gecleand'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "#label toekennen aan postive en  negative\n",
    "df['output'] = df['output'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['input'], df['output'], test_size=0.3)\n",
    "\n",
    "\n",
    "# Data opsplitsen in woorden\n",
    "data = df['Gecleand'].str.split(\" \", expand=False)\n",
    "\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)\n",
    "\n",
    "\n",
    "\n",
    "# TO DO: Words bestaat uit losse letters en getallen ipv woorden\n",
    "words = set(w2v_model.wv.index_to_key)\n",
    "print(words)\n",
    "\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_train])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                        for ls in X_test])\n",
    "\n",
    "#iets aan een list toevoegen\n",
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
    "\n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(100, dtype=float))\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_vect_avg, y_train.values)\n",
    "\n",
    "print('Test Accuracy: ', lr_clf.score(X_test_vect_avg, y_test.values))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            lr_clf.predict(X_test_vect_avg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c59149",
   "metadata": {},
   "source": [
    "# Medium database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"C:\\\\Users\\\\shirl\\\\Desktop\\\\MovieReactionDS_medium.json\")\n",
    "\n",
    "#Controleren op null waardes\n",
    "df.isna().sum()\n",
    "\n",
    "#LEESTEKENS \n",
    "df[\"Gecleand\"] = df['input'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#De kolom `Gecleand` alles in kleine letters zetten\n",
    "df['Gecleand'] = df['Gecleand'].str.lower()\n",
    "#print(df)\n",
    "\n",
    "#stopwoorden eruit halen\n",
    "stop = stopwords.words('english')\n",
    "df['Gecleand'] = df['Gecleand'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "#label toekennen aan postive en  negative\n",
    "df['output'] = df['output'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['input'], df['output'], test_size=0.3)\n",
    "\n",
    "\n",
    "# Data opsplitsen in woorden\n",
    "data = df['Gecleand'].str.split(\" \", expand=False)\n",
    "\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)\n",
    "\n",
    "\n",
    "\n",
    "# TO DO: Words bestaat uit losse letter ipv woorden\n",
    "words = set(w2v_model.wv.index_to_key)\n",
    "print(words)\n",
    "\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_train])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                        for ls in X_test])\n",
    "\n",
    "#iets aan een list toevoegen\n",
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
    "\n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(100, dtype=float))\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_vect_avg, y_train.values)\n",
    "\n",
    "print('Test Accuracy: ', lr_clf.score(X_test_vect_avg, y_test.values))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            lr_clf.predict(X_test_vect_avg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3fe4d",
   "metadata": {},
   "source": [
    "# Grote database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"C:\\\\Users\\\\shirl\\\\Desktop\\\\MovieReactionDS.json\")\n",
    "\n",
    "#Controleren op null waardes\n",
    "df.isna().sum()\n",
    "\n",
    "#LEESTEKENS \n",
    "df[\"Gecleand\"] = df['input'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#De kolom `Gecleand` alles in kleine letters zetten\n",
    "df['Gecleand'] = df['Gecleand'].str.lower()\n",
    "#print(df)\n",
    "\n",
    "#stopwoorden eruit halen\n",
    "stop = stopwords.words('english')\n",
    "df['Gecleand'] = df['Gecleand'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "#label toekennen aan postive en  negative\n",
    "df['output'] = df['output'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['input'], df['output'], test_size=0.3)\n",
    "\n",
    "\n",
    "# Data opsplitsen in woorden\n",
    "data = df['Gecleand'].str.split(\" \", expand=False)\n",
    "\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)\n",
    "\n",
    "\n",
    "\n",
    "# TO DO: Words bestaat uit losse letter ipv woorden\n",
    "words = set(w2v_model.wv.index_to_key)\n",
    "print(words)\n",
    "\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_train])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                        for ls in X_test])\n",
    "\n",
    "#iets aan een list toevoegen\n",
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
    "\n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(100, dtype=float))\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_vect_avg, y_train.values)\n",
    "\n",
    "print('Test Accuracy: ', lr_clf.score(X_test_vect_avg, y_test.values))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            lr_clf.predict(X_test_vect_avg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798561b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd6024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1674692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
